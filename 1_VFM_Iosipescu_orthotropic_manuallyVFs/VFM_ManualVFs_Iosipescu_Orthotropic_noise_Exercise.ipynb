{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Fields Method: Iosipescu Test for Orthotropic Materials\n",
    "## Student Implementation Exercise\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the VFM principle for material identification\n",
    "- Implement three different sets of virtual fields\n",
    "- Analyze noise sensitivity through Monte Carlo simulation\n",
    "- Compare different VF strategies\n",
    "\n",
    "### Background\n",
    "The Virtual Fields Method (VFM) allows identification of material parameters from full-field measurements.\n",
    "\n",
    "**VFM Equation for orthotropic materials:**\n",
    "$$Q_{11} \\int_S \\varepsilon_1 \\varepsilon_1^* dS + Q_{22} \\int_S \\varepsilon_2 \\varepsilon_2^* dS + Q_{12} \\int_S (\\varepsilon_1 \\varepsilon_2^* + \\varepsilon_2 \\varepsilon_1^*) dS + Q_{66} \\int_S \\varepsilon_6 \\varepsilon_6^* dS = \\int_{L_f} T_i u_i^* dl$$\n",
    "\n",
    "Where:\n",
    "- $Q_{ij}$ are the stiffness parameters to identify\n",
    "- $\\varepsilon$ are the measured strain fields\n",
    "- $\\varepsilon^*$ are the virtual strain fields\n",
    "- We need 4 independent virtual fields to solve for 4 unknowns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:40:53.635974Z",
     "start_time": "2025-10-05T20:40:53.631661Z"
    }
   },
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "from scipy import io\n",
    "from io import StringIO\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.rcParams['font.size'] = 12\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 1: Class Provided Data Loading"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:40:55.852321Z",
     "start_time": "2025-10-05T20:40:55.824156Z"
    }
   },
   "source": [
    "class IosipescuVFMNoise:\n",
    "    \"\"\"\n",
    "    VFM analysis for Iosipescu test with noise simulation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_source='csv'):\n",
    "        self.data_source = data_source\n",
    "        self.data = {}\n",
    "        self.results = {}\n",
    "        self.noise_results = {}\n",
    "    \n",
    "    def load_data_from_csv(self, csv_dir='.'):\n",
    "        \"\"\"Load data from CSV files (local or URL)\"\"\"\n",
    "\n",
    "        # Determine if we're working with URL or local path\n",
    "        is_url = csv_dir.startswith('http')\n",
    "\n",
    "        # Construct paths\n",
    "        if is_url:\n",
    "            base = csv_dir.rstrip('/')\n",
    "            scalar_path = f\"{base}/scalarsFE.csv\"\n",
    "            fem_path = f\"{base}/FEM2VFM.csv\"\n",
    "        else:\n",
    "            scalar_path = os.path.join(csv_dir, 'scalarsFE.csv')\n",
    "            fem_path = os.path.join(csv_dir, 'FEM2VFM.csv')\n",
    "\n",
    "        # Load scalar parameters\n",
    "        try:\n",
    "            if is_url:\n",
    "                response = requests.get(scalar_path)\n",
    "                response.raise_for_status()\n",
    "                content = response.text\n",
    "            else:\n",
    "                with open(scalar_path, 'r') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "            for line in content.split('\\n'):\n",
    "                if '=' in line:\n",
    "                    key, value = line.strip().split('=')\n",
    "                    key = key.strip()\n",
    "                    value = float(value.strip())\n",
    "\n",
    "                    if key == 'Length':\n",
    "                        self.data['L'] = value\n",
    "                    elif key == 'Width':\n",
    "                        self.data['w'] = value\n",
    "                    elif key == 'Thick':\n",
    "                        self.data['t'] = value\n",
    "                    elif key == 'P':\n",
    "                        self.data['F'] = value\n",
    "\n",
    "            print(f\"Loaded scalars from: {scalar_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {scalar_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Load FEM data\n",
    "        try:\n",
    "            fem_data = pd.read_csv(fem_path, sep=r'\\s+')\n",
    "\n",
    "            self.data['X1'] = fem_data['X_Coord'].values\n",
    "            self.data['X2'] = fem_data['Y_Coord'].values\n",
    "            self.data['Eps1'] = fem_data['Eps_X'].values\n",
    "            self.data['Eps2'] = fem_data['Eps_Y'].values\n",
    "            self.data['Eps6'] = fem_data['Eps_XY'].values\n",
    "\n",
    "            print(f\"Loaded FEM data from: {fem_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {fem_path}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _validate_data(self):\n",
    "        \"\"\"Validate loaded data (PROVIDED)\"\"\"\n",
    "        print(\"Data validation:\")\n",
    "        for key, value in self.data.items():\n",
    "            if np.isscalar(value):\n",
    "                print(f\"  {key}: {value}\")\n",
    "            else:\n",
    "                arr = np.array(value)\n",
    "                print(f\"  {key}: shape {arr.shape}, range [{arr.min():.3f}, {arr.max():.3f}]\")\n",
    "        \n",
    "        X1, X2 = self.data['X1'], self.data['X2']\n",
    "        L, w = self.data['L'], self.data['w']\n",
    "        print(f\"\\nCoordinate validation:\")\n",
    "        print(f\"  X1 range: [{X1.min():.3f}, {X1.max():.3f}], Expected: [0, {L}]\")\n",
    "        print(f\"  X2 range: [{X2.min():.3f}, {X2.max():.3f}], Expected: [approx Â±{w/2}]\")\n",
    "    \n",
    "    def load_data(self, source_path='.'):\n",
    "        \"\"\"Load data wrapper (PROVIDED)\"\"\"\n",
    "        if self.data_source == 'csv':\n",
    "            self.load_data_from_csv(source_path)\n",
    "        else:\n",
    "            raise ValueError(\"Only CSV loading implemented\")\n",
    "\n",
    "    def run_noise_analysis(self, noise_amplitude=10e-4, n_iterations=30, Q_ref=None, material_name=\"reference\"):\n",
    "        \"\"\"\n",
    "        Run VFM analysis with white noise simulation over multiple iterations\n",
    "\n",
    "        Parameters:\n",
    "        noise_amplitude: Standard deviation of Gaussian white noise (default: 10e-4)\n",
    "        n_iterations: Number of Monte Carlo iterations (default: 30)\n",
    "        Q_ref: Reference values for comparison (GPa)\n",
    "        material_name: Name of the material for reference\n",
    "        \"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"VFM NOISE ANALYSIS - WHITE NOISE SIMULATION\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Noise amplitude (std dev): {noise_amplitude:.1e}\")\n",
    "        print(f\"Number of iterations: {n_iterations}\")\n",
    "        print(f\"Material: {material_name}\")\n",
    "\n",
    "        # Get original strain data\n",
    "        Eps1_orig = self.data['Eps1']\n",
    "        Eps2_orig = self.data['Eps2']\n",
    "        Eps6_orig = self.data['Eps6']\n",
    "\n",
    "        print(f\"\\nOriginal strain data shapes:\")\n",
    "        print(f\"  Eps1: {Eps1_orig.shape}\")\n",
    "        print(f\"  Eps2: {Eps2_orig.shape}\")\n",
    "        print(f\"  Eps6: {Eps6_orig.shape}\")\n",
    "\n",
    "        # Initialize result arrays\n",
    "        Q11_set1, Q22_set1, Q12_set1, Q66_set1 = [], [], [], []\n",
    "        Q11_set2, Q22_set2, Q12_set2, Q66_set2 = [], [], [], []\n",
    "        Q11_set3, Q22_set3, Q12_set3, Q66_set3 = [], [], [], []\n",
    "\n",
    "        print(f\"\\nRunning {n_iterations} iterations with white noise...\")\n",
    "        successful_iterations = 0\n",
    "\n",
    "        for i in range(n_iterations):\n",
    "            if (i + 1) % 10 == 0 or i == 0:\n",
    "                print(f\"  Iteration {i + 1}/{n_iterations}\")\n",
    "\n",
    "            # Add Gaussian white noise to strain data\n",
    "            noise1 = np.random.randn(*Eps1_orig.shape) * noise_amplitude\n",
    "            noise2 = np.random.randn(*Eps2_orig.shape) * noise_amplitude\n",
    "            noise6 = np.random.randn(*Eps6_orig.shape) * noise_amplitude\n",
    "\n",
    "            Eps1_noisy = Eps1_orig + noise1\n",
    "            Eps2_noisy = Eps2_orig + noise2\n",
    "            Eps6_noisy = Eps6_orig + noise6\n",
    "\n",
    "            # Run all three virtual field sets\n",
    "            try:\n",
    "                # Set 1\n",
    "                Q1 = self.virtual_fields_set_1(Eps1_noisy, Eps2_noisy, Eps6_noisy)\n",
    "                Q11_set1.append(Q1[0])\n",
    "                Q22_set1.append(Q1[1])\n",
    "                Q12_set1.append(Q1[2])\n",
    "                Q66_set1.append(Q1[3])\n",
    "\n",
    "                # Set 2\n",
    "                Q2 = self.virtual_fields_set_2(Eps1_noisy, Eps2_noisy, Eps6_noisy)\n",
    "                Q11_set2.append(Q2[0])\n",
    "                Q22_set2.append(Q2[1])\n",
    "                Q12_set2.append(Q2[2])\n",
    "                Q66_set2.append(Q2[3])\n",
    "\n",
    "                # Set 3\n",
    "                Q3 = self.virtual_fields_set_3(Eps1_noisy, Eps2_noisy, Eps6_noisy)\n",
    "                Q11_set3.append(Q3[0])\n",
    "                Q22_set3.append(Q3[1])\n",
    "                Q12_set3.append(Q3[2])\n",
    "                Q66_set3.append(Q3[3])\n",
    "\n",
    "                successful_iterations += 1\n",
    "\n",
    "            except np.linalg.LinAlgError:\n",
    "                print(f\"    Warning: Singular matrix at iteration {i + 1}, skipping...\")\n",
    "                continue\n",
    "\n",
    "        print(f\"Completed {successful_iterations}/{n_iterations} successful iterations\")\n",
    "\n",
    "        # Convert to numpy arrays and to GPa\n",
    "        Q11_set1 = np.array(Q11_set1) / 1e3\n",
    "        Q22_set1 = np.array(Q22_set1) / 1e3\n",
    "        Q12_set1 = np.array(Q12_set1) / 1e3\n",
    "        Q66_set1 = np.array(Q66_set1) / 1e3\n",
    "\n",
    "        Q11_set2 = np.array(Q11_set2) / 1e3\n",
    "        Q22_set2 = np.array(Q22_set2) / 1e3\n",
    "        Q12_set2 = np.array(Q12_set2) / 1e3\n",
    "        Q66_set2 = np.array(Q66_set2) / 1e3\n",
    "\n",
    "        Q11_set3 = np.array(Q11_set3) / 1e3\n",
    "        Q22_set3 = np.array(Q22_set3) / 1e3\n",
    "        Q12_set3 = np.array(Q12_set3) / 1e3\n",
    "        Q66_set3 = np.array(Q66_set3) / 1e3\n",
    "\n",
    "        # Store results\n",
    "        self.noise_results = {\n",
    "            'set1': {'Q11': Q11_set1, 'Q22': Q22_set1, 'Q12': Q12_set1, 'Q66': Q66_set1},\n",
    "            'set2': {'Q11': Q11_set2, 'Q22': Q22_set2, 'Q12': Q12_set2, 'Q66': Q66_set2},\n",
    "            'set3': {'Q11': Q11_set3, 'Q22': Q22_set3, 'Q12': Q12_set3, 'Q66': Q66_set3}\n",
    "        }\n",
    "\n",
    "        # Store the last iteration's noisy strain data for plotting\n",
    "        self.Eps1_noisy = Eps1_noisy\n",
    "        self.Eps2_noisy = Eps2_noisy\n",
    "        self.Eps6_noisy = Eps6_noisy\n",
    "\n",
    "        # Calculate and display statistics\n",
    "        self._display_statistics(Q_ref, material_name)\n",
    "\n",
    "        return self.noise_results\n",
    "\n",
    "    def _display_statistics(self, Q_ref=None, material_name=\"reference\"):\n",
    "        \"\"\"Display statistical results\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 90)\n",
    "        print(\"STATISTICAL RESULTS\")\n",
    "        print(\"=\" * 90)\n",
    "\n",
    "        # Parameter names\n",
    "        params = ['Q11', 'Q22', 'Q12', 'Q66']\n",
    "\n",
    "        # Display results for each virtual field set\n",
    "        for set_num, set_name in enumerate(['set1', 'set2', 'set3'], 1):\n",
    "            print(f\"\\nVirtual Field Set {set_num}:\")\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"{'Param':<6} {'Mean':<10} {'Std':<10} {'CV%':<10}\", end=\"\")\n",
    "            if Q_ref is not None:\n",
    "                print(f\" {'Ref':<10} {'Error%':<10}\")\n",
    "            else:\n",
    "                print()\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "            for i, param in enumerate(params):\n",
    "                values = self.noise_results[set_name][param]\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "                cv_val = (std_val / mean_val) * 100 if mean_val != 0 else 0\n",
    "\n",
    "                print(f\"{param:<6} {mean_val:<10.3f} {std_val:<10.4f} {cv_val:<10.3f}\", end=\"\")\n",
    "\n",
    "                if Q_ref is not None:\n",
    "                    error_pct = abs(mean_val - Q_ref[i]) / Q_ref[i] * 100 if Q_ref[i] != 0 else 0\n",
    "                    print(f\" {Q_ref[i]:<10.3f} {error_pct:<10.3f}\")\n",
    "                else:\n",
    "                    print()\n",
    "\n",
    "        # Display noise robustness comparison\n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(\"NOISE ROBUSTNESS COMPARISON (Coefficient of Variation %)\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Param':<8} {'Set 1':<12} {'Set 2':<12} {'Set 3':<12} {'Best Set':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        for i, param in enumerate(params):\n",
    "            cv1 = (np.std(self.noise_results['set1'][param]) / np.mean(self.noise_results['set1'][param])) * 100\n",
    "            cv2 = (np.std(self.noise_results['set2'][param]) / np.mean(self.noise_results['set2'][param])) * 100\n",
    "            cv3 = (np.std(self.noise_results['set3'][param]) / np.mean(self.noise_results['set3'][param])) * 100\n",
    "\n",
    "            cvs = [cv1, cv2, cv3]\n",
    "            best_set = np.argmin(cvs) + 1\n",
    "\n",
    "            print(f\"{param:<8} {cv1:<12.3f} {cv2:<12.3f} {cv3:<12.3f} Set {best_set:<6}\")\n",
    "\n",
    "        # Overall summary\n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(\"SUMMARY COMPARISON TABLE (GPa)\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Parameter':<10} {'Set 1':<12} {'Set 2':<12} {'Set 3':<12}\", end=\"\")\n",
    "        if Q_ref is not None:\n",
    "            print(f\" {'Reference':<12}\")\n",
    "        else:\n",
    "            print()\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        for i, param in enumerate(params):\n",
    "            mean1 = np.mean(self.noise_results['set1'][param])\n",
    "            mean2 = np.mean(self.noise_results['set2'][param])\n",
    "            mean3 = np.mean(self.noise_results['set3'][param])\n",
    "\n",
    "            print(f\"{param:<10} {mean1:<12.3f} {mean2:<12.3f} {mean3:<12.3f}\", end=\"\")\n",
    "            if Q_ref is not None:\n",
    "                print(f\" {Q_ref[i]:<12.3f}\")\n",
    "            else:\n",
    "                print()\n",
    "\n",
    "    def plot_results(self, save_plots=True):\n",
    "        \"\"\"Plot histograms of identified parameters\"\"\"\n",
    "        if not self.noise_results:\n",
    "            print(\"No noise analysis results to plot. Run noise analysis first.\")\n",
    "            return\n",
    "\n",
    "        params = ['Q11', 'Q22', 'Q12', 'Q66']\n",
    "        param_units = ['GPa', 'GPa', 'GPa', 'GPa']\n",
    "\n",
    "        # Set up plotting parameters\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        colors = ['blue', 'red', 'green']\n",
    "        alphas = [0.6, 0.6, 0.6]\n",
    "\n",
    "        for i, param in enumerate(params):\n",
    "            ax = axes[i]\n",
    "\n",
    "            # Plot histograms for all three sets\n",
    "            ax.hist(self.noise_results['set1'][param], alpha=alphas[0], label='Set 1',\n",
    "                    bins=20, density=True, color=colors[0], edgecolor='black', linewidth=0.5)\n",
    "            ax.hist(self.noise_results['set2'][param], alpha=alphas[1], label='Set 2',\n",
    "                    bins=20, density=True, color=colors[1], edgecolor='black', linewidth=0.5)\n",
    "            ax.hist(self.noise_results['set3'][param], alpha=alphas[2], label='Set 3',\n",
    "                    bins=20, density=True, color=colors[2], edgecolor='black', linewidth=0.5)\n",
    "\n",
    "            ax.set_xlabel(f'{param} ({param_units[i]})', fontsize=14)\n",
    "            ax.set_ylabel('Probability Density', fontsize=14)\n",
    "            ax.set_title(f'Distribution of {param} with White Noise', fontsize=16, fontweight='bold')\n",
    "            ax.legend(fontsize=12)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "            # Add statistics text box\n",
    "            mean1 = np.mean(self.noise_results['set1'][param])\n",
    "            mean2 = np.mean(self.noise_results['set2'][param])\n",
    "            mean3 = np.mean(self.noise_results['set3'][param])\n",
    "\n",
    "            std1 = np.std(self.noise_results['set1'][param])\n",
    "            std2 = np.std(self.noise_results['set2'][param])\n",
    "            std3 = np.std(self.noise_results['set3'][param])\n",
    "\n",
    "            stats_text = f'Set 1: Î¼={mean1:.3f}, Ï={std1:.4f}\\n'\n",
    "            stats_text += f'Set 2: Î¼={mean2:.3f}, Ï={std2:.4f}\\n'\n",
    "            stats_text += f'Set 3: Î¼={mean3:.3f}, Ï={std3:.4f}'\n",
    "\n",
    "            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_plots:\n",
    "            plt.savefig('vfm_noise_analysis_results.png', dpi=300, bbox_inches='tight',\n",
    "                        facecolor='white', edgecolor='none')\n",
    "            print(\"Histogram plot saved as 'vfm_noise_analysis_results.png'\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_strain_fields(self, save_path='strain_fields_with_noise.png'):\n",
    "        \"\"\"Plot the strain field distributions with noise\"\"\"\n",
    "        if not hasattr(self, 'Eps1_noisy'):\n",
    "            print(\"No noisy strain data available. Run noise analysis first.\")\n",
    "            return\n",
    "\n",
    "        FS = 22\n",
    "        cor = 'BrBG'\n",
    "\n",
    "        # Disable LaTeX rendering in Jupyter\n",
    "        plt.rcParams['text.usetex'] = False\n",
    "        plt.rcParams['font.size'] = FS\n",
    "\n",
    "        # Get data\n",
    "        X1 = self.data['X1'].flatten()\n",
    "        X2 = self.data['X2'].flatten()\n",
    "        strain_data = [self.Eps1_noisy.flatten(), self.Eps2_noisy.flatten(), self.Eps6_noisy.flatten()]\n",
    "\n",
    "        # Use simple labels without LaTeX (or use matplotlib's mathtext)\n",
    "        strain_labels = ['Îµâ (with noise)', 'Îµâ (with noise)', 'Îµâ (with noise)']\n",
    "        # Or use matplotlib's mathtext (doesn't require LaTeX):\n",
    "        # strain_labels = [r'$\\varepsilon_1$ (with noise)', r'$\\varepsilon_2$ (with noise)', r'$\\varepsilon_6$ (with noise)']\n",
    "\n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "        # Plot each strain component\n",
    "        for i, (data, label, ax) in enumerate(zip(strain_data, strain_labels, axes)):\n",
    "            vmin, vmax = np.min(data), np.max(data)\n",
    "            im = ax.tricontourf(X1, X2, data, levels=20, cmap=cor, vmin=vmin, vmax=vmax)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_title(label, fontsize=FS + 2)\n",
    "            ax.set_xlabel('xâ (mm)', fontsize=FS)  # or r'$x_1$ (mm)' with mathtext\n",
    "            ax.set_ylabel('xâ (mm)', fontsize=FS)  # or r'$x_2$ (mm)' with mathtext\n",
    "            ax.tick_params(labelsize=FS - 4)\n",
    "\n",
    "            cbar = plt.colorbar(im, ax=ax, shrink=0.6, aspect=30, pad=0.05, fraction=0.04)\n",
    "            cbar.ax.tick_params(labelsize=FS - 4)\n",
    "            cbar.formatter.set_powerlimits((0, 0))\n",
    "            cbar.update_ticks()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight',\n",
    "                    facecolor='white', edgecolor='none')\n",
    "        print(f\"Strain field plot saved as '{save_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    def run_clean_analysis_comparison(self, Q_ref=None, material_name=\"reference\"):\n",
    "        \"\"\"Run analysis without noise for comparison\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CLEAN DATA ANALYSIS (NO NOISE) FOR COMPARISON\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Get original strain data\n",
    "        Eps1_orig = self.data['Eps1']\n",
    "        Eps2_orig = self.data['Eps2']\n",
    "        Eps6_orig = self.data['Eps6']\n",
    "\n",
    "        try:\n",
    "            # Run all three virtual field sets with clean data\n",
    "            Q1_clean = self.virtual_fields_set_1(Eps1_orig, Eps2_orig, Eps6_orig)\n",
    "            Q2_clean = self.virtual_fields_set_2(Eps1_orig, Eps2_orig, Eps6_orig)\n",
    "            Q3_clean = self.virtual_fields_set_3(Eps1_orig, Eps2_orig, Eps6_orig)\n",
    "\n",
    "            # Convert to GPa\n",
    "            Q1_clean_gpa = Q1_clean / 1e3\n",
    "            Q2_clean_gpa = Q2_clean / 1e3\n",
    "            Q3_clean_gpa = Q3_clean / 1e3\n",
    "\n",
    "            print(\"Clean data results (GPa):\")\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"{'Param':<8} {'Set 1':<12} {'Set 2':<12} {'Set 3':<12}\", end=\"\")\n",
    "            if Q_ref is not None:\n",
    "                print(f\" {'Reference':<12}\")\n",
    "            else:\n",
    "                print()\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "            params = ['Q11', 'Q22', 'Q12', 'Q66']\n",
    "            for i, param in enumerate(params):\n",
    "                print(f\"{param:<8} {Q1_clean_gpa[i]:<12.3f} {Q2_clean_gpa[i]:<12.3f} {Q3_clean_gpa[i]:<12.3f}\", end=\"\")\n",
    "                if Q_ref is not None:\n",
    "                    print(f\" {Q_ref[i]:<12.3f}\")\n",
    "                else:\n",
    "                    print()\n",
    "\n",
    "            return {'set1': Q1_clean_gpa, 'set2': Q2_clean_gpa, 'set3': Q3_clean_gpa}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in clean analysis: {e}\")\n",
    "            return None"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Configuration Parameters"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:41:06.031783Z",
     "start_time": "2025-10-05T20:41:06.028342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Noise analysis parameters\n",
    "noise_amplitude = 10e-4  # Standard deviation of Gaussian white noise\n",
    "n_iterations = 30        # Number of Monte Carlo iterations\n",
    "\n",
    "# Reference values (in GPa)\n",
    "Q_ref = np.array([15.536, 1.965, 0.926, 1.109])  # Q11, Q22, Q12, Q66\n",
    "material_name = \"Wood (from working VFM code)\"\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"NOISE ANALYSIS CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Noise amplitude (std dev): {noise_amplitude:.1e}\")\n",
    "print(f\"Monte Carlo iterations: {n_iterations}\")\n",
    "print(f\"Material: {material_name}\")\n",
    "print(f\"Reference values (GPa): Q11={Q_ref[0]:.3f}, Q22={Q_ref[1]:.3f}, Q12={Q_ref[2]:.3f}, Q66={Q_ref[3]:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NOISE ANALYSIS CONFIGURATION\n",
      "============================================================\n",
      "Noise amplitude (std dev): 1.0e-03\n",
      "Monte Carlo iterations: 30\n",
      "Material: Wood (from working VFM code)\n",
      "Reference values (GPa): Q11=15.536, Q22=1.965, Q12=0.926, Q66=1.109\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Load Data"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:41:13.921988Z",
     "start_time": "2025-10-05T20:41:10.053701Z"
    }
   },
   "source": [
    "# Initialize noise analysis\n",
    "vfm_noise = IosipescuVFMNoise(data_source='csv')\n",
    "\n",
    "# Base URL\n",
    "BASE_URL = 'https://userweb.fct.unl.pt/~jmc.xavier/CISM_C2516/1_VFM_Iosipescu_orthotropic_manuallyVFs/'\n",
    "\n",
    "# Load data from current directory\n",
    "# vfm_noise.load_data_from_csv('.')\n",
    "\n",
    "try:\n",
    "    vfm_noise.load_data_from_csv(BASE_URL)\n",
    "    print(\"Data loaded successfully from URL!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Still works with local files\n",
    "# vfm_noise.load_data_from_csv('.')\n",
    "# try:\n",
    "#     vfm_noise.load_data('.')  # Load from current directory\n",
    "#     print(\"\\nData loaded successfully!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading data: {e}\")\n",
    "#     print(\"Make sure 'scalarsFE.csv' and 'FEM2VFM.csv' are in the current directory\")\n",
    "#\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded scalars from: https://userweb.fct.unl.pt/~jmc.xavier/CISM_C2516/1_VFM_Iosipescu_orthotropic_manuallyVFs/scalarsFE.csv\n",
      "Loaded FEM data from: https://userweb.fct.unl.pt/~jmc.xavier/CISM_C2516/1_VFM_Iosipescu_orthotropic_manuallyVFs/FEM2VFM.csv\n",
      "Data loaded successfully from URL!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement Virtual Field Sets\n",
    "\n",
    "### Virtual Field Set 1\n",
    "\n",
    "You need to implement the first set of virtual fields:\n",
    "\n",
    "**Displacement fields:**\n",
    "- VF1: $u_1^* = 0, \\quad u_2^* = -x_1$\n",
    "- VF2: $u_1^* = x_1(L-x_1)x_2, \\quad u_2^* = \\frac{x_1^3}{3} - \\frac{Lx_1^2}{2}$\n",
    "- VF3: $u_1^* = 0, \\quad u_2^* = x_1(L-x_1)x_2$\n",
    "- VF4: $u_1^* = \\frac{L}{2\\pi}\\sin(2\\pi x_1/L), \\quad u_2^* = 0$\n",
    "\n",
    "**Corresponding strain fields:**\n",
    "- VF1: $\\varepsilon_1^* = 0, \\quad \\varepsilon_2^* = 0, \\quad \\varepsilon_6^* = -1$\n",
    "- VF2: $\\varepsilon_1^* = (L-2x_1)x_2, \\quad \\varepsilon_2^* = 0, \\quad \\varepsilon_6^* = 0$\n",
    "- VF3: $\\varepsilon_1^* = 0, \\quad \\varepsilon_2^* = x_1(L-x_1), \\quad \\varepsilon_6^* = (L-2x_1)x_2$\n",
    "- VF4: $\\varepsilon_1^* = \\cos(2\\pi x_1/L), \\quad \\varepsilon_2^* = 0, \\quad \\varepsilon_6^* = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def virtual_fields_set_1(self, Eps1, Eps2, Eps6):\n",
    "    \"\"\"\n",
    "    First set of virtual fields\n",
    "    \n",
    "    TODO: Implement this method\n",
    "    \n",
    "    Steps:\n",
    "    1. Extract coordinates and geometry from self.data\n",
    "    2. Initialize 4x4 matrix A and 4x1 vector B\n",
    "    3. For each virtual field, compute the contributions to A and B\n",
    "    4. Solve the system AQ = B to get [Q11, Q22, Q12, Q66]\n",
    "    \n",
    "    Hints:\n",
    "    - Use np.mean() to compute spatial averages (integral approximation)\n",
    "    - Right-hand side B comes from external work: F/(w*t) or F*LÂ²/(6*w*t)\n",
    "    - Use np.linalg.solve(A, B) to solve the system\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    Q : ndarray\n",
    "        Array [Q11, Q22, Q12, Q66] in MPa\n",
    "    \"\"\"\n",
    "    # Get data\n",
    "    X1 = self.data['X1']\n",
    "    X2 = self.data['X2']\n",
    "    L = self.data['L']\n",
    "    w = self.data['w']\n",
    "    t = self.data['t']\n",
    "    F = self.data['F']\n",
    "    \n",
    "    # Initialize system\n",
    "    A = np.zeros((4, 4))\n",
    "    B = np.zeros(4)\n",
    "    \n",
    "    # ==========================================\n",
    "    # TODO: Implement VF1\n",
    "    # Îµ1* = 0, Îµ2* = 0, Îµ6* = -1\n",
    "    # ==========================================\n",
    "    # A[0, 0] = ?  # Q11 coefficient\n",
    "    # A[0, 1] = ?  # Q22 coefficient\n",
    "    # A[0, 2] = ?  # Q12 coefficient\n",
    "    # A[0, 3] = ?  # Q66 coefficient\n",
    "    # B[0] = ?\n",
    "    \n",
    "    # ==========================================\n",
    "    # TODO: Implement VF2\n",
    "    # Îµ1* = (L-2x1)x2, Îµ2* = 0, Îµ6* = 0\n",
    "    # ==========================================\n",
    "    # vf2_eps1_star = ?\n",
    "    # A[1, 0] = ?\n",
    "    # A[1, 1] = ?\n",
    "    # A[1, 2] = ?\n",
    "    # A[1, 3] = ?\n",
    "    # B[1] = ?\n",
    "    \n",
    "    # ==========================================\n",
    "    # TODO: Implement VF3\n",
    "    # Îµ1* = 0, Îµ2* = x1(L-x1), Îµ6* = (L-2x1)x2\n",
    "    # ==========================================\n",
    "    \n",
    "    # ==========================================\n",
    "    # TODO: Implement VF4\n",
    "    # Îµ1* = cos(2Ïx1/L), Îµ2* = 0, Îµ6* = 0\n",
    "    # ==========================================\n",
    "    \n",
    "    # Solve system\n",
    "    # TODO: Q = np.linalg.solve(A, B)\n",
    "    \n",
    "    raise NotImplementedError(\"You need to implement this method!\")\n",
    "    # return Q\n",
    "\n",
    "# Add method to class\n",
    "IosipescuVFM.virtual_fields_set_1 = virtual_fields_set_1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Field Set 2 (Modified 4th field)\n",
    "\n",
    "**TODO:** Implement Set 2 with modified VF4:\n",
    "- VF4: $u_1^* = 0, \\quad u_2^* = x_1(L-x_1)x_2^3$\n",
    "- VF4 strains: $\\varepsilon_1^* = 0, \\quad \\varepsilon_2^* = 3x_1(L-x_1)x_2^2, \\quad \\varepsilon_6^* = (L-2x_1)x_2^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def virtual_fields_set_2(self, Eps1, Eps2, Eps6):\n",
    "    \"\"\"\n",
    "    Second set of virtual fields (modified 4th field)\n",
    "    \n",
    "    TODO: Implement this method\n",
    "    Hint: VF1-3 are the same as Set 1, only VF4 changes\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"You need to implement this method!\")\n",
    "\n",
    "IosipescuVFM.virtual_fields_set_2 = virtual_fields_set_2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Field Set 3 (Modified 1st field)\n",
    "\n",
    "**TODO:** Implement Set 3 with modified VF1:\n",
    "- VF1: $u_1^* = 0, \\quad u_2^* = -x_1^3$\n",
    "- VF1 strains: $\\varepsilon_1^* = 0, \\quad \\varepsilon_2^* = -3x_1^2, \\quad \\varepsilon_6^* = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def virtual_fields_set_3(self, Eps1, Eps2, Eps6):\n",
    "    \"\"\"\n",
    "    Third set of virtual fields (modified 1st field)\n",
    "    \n",
    "    TODO: Implement this method\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"You need to implement this method!\")\n",
    "\n",
    "IosipescuVFM.virtual_fields_set_3 = virtual_fields_set_3"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Test Your Implementation (Clean Data)\n",
    "\n",
    "Once you've implemented the virtual field methods, test them with clean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run_clean_analysis(self, Q_ref=None, material_name=\"reference\"):\n",
    "    \"\"\"Run analysis without noise (PROVIDED)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CLEAN DATA ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    Eps1 = self.data['Eps1']\n",
    "    Eps2 = self.data['Eps2']\n",
    "    Eps6 = self.data['Eps6']\n",
    "    \n",
    "    try:\n",
    "        Q1 = self.virtual_fields_set_1(Eps1, Eps2, Eps6)\n",
    "        Q2 = self.virtual_fields_set_2(Eps1, Eps2, Eps6)\n",
    "        Q3 = self.virtual_fields_set_3(Eps1, Eps2, Eps6)\n",
    "        \n",
    "        # Convert to GPa\n",
    "        Q1_gpa = Q1 / 1e3\n",
    "        Q2_gpa = Q2 / 1e3\n",
    "        Q3_gpa = Q3 / 1e3\n",
    "        \n",
    "        print(\"\\nResults (GPa):\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"{'Param':<8} {'Set 1':<12} {'Set 2':<12} {'Set 3':<12}\", end=\"\")\n",
    "        if Q_ref is not None:\n",
    "            print(f\" {'Reference':<12}\")\n",
    "        else:\n",
    "            print()\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        params = ['Q11', 'Q22', 'Q12', 'Q66']\n",
    "        for i, param in enumerate(params):\n",
    "            print(f\"{param:<8} {Q1_gpa[i]:<12.3f} {Q2_gpa[i]:<12.3f} {Q3_gpa[i]:<12.3f}\", end=\"\")\n",
    "            if Q_ref is not None:\n",
    "                print(f\" {Q_ref[i]:<12.3f}\")\n",
    "            else:\n",
    "                print()\n",
    "        \n",
    "        return {'set1': Q1_gpa, 'set2': Q2_gpa, 'set3': Q3_gpa}\n",
    "        \n",
    "    except NotImplementedError as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "        print(\"Please implement the virtual field methods first!\")\n",
    "        return None\n",
    "\n",
    "IosipescuVFM.run_clean_analysis = run_clean_analysis"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Reference values from FE model (GPa)\n",
    "Q_ref = np.array([15.536, 1.965, 0.926, 1.109])\n",
    "\n",
    "# Test your implementation\n",
    "clean_results = vfm.run_clean_analysis(Q_ref=Q_ref, material_name=\"Wood\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Results:\n",
    "\n",
    "Your implementation should give results close to:\n",
    "- Q11 â 15.5 GPa\n",
    "- Q22 â 1.96 GPa  \n",
    "- Q12 â 0.92-0.98 GPa (varies by set)\n",
    "- Q66 â 1.11 GPa\n",
    "\n",
    "If your results are significantly different, check:\n",
    "1. Sign conventions in the virtual strains\n",
    "2. Averaging using `np.mean()`\n",
    "3. Right-hand side values (external work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Noise Analysis\n",
    "\n",
    "This section analyzes robustness to measurement noise using Monte Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run_noise_analysis(self, noise_amplitude=10e-4, n_iterations=30, Q_ref=None):\n",
    "    \"\"\"Monte Carlo noise analysis (PROVIDED)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"NOISE SENSITIVITY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Noise amplitude (std dev): {noise_amplitude:.1e}\")\n",
    "    print(f\"Number of iterations: {n_iterations}\")\n",
    "    \n",
    "    Eps1_orig = self.data['Eps1']\n",
    "    Eps2_orig = self.data['Eps2']\n",
    "    Eps6_orig = self.data['Eps6']\n",
    "    \n",
    "    # Initialize result arrays\n",
    "    Q11_set1, Q22_set1, Q12_set1, Q66_set1 = [], [], [], []\n",
    "    Q11_set2, Q22_set2, Q12_set2, Q66_set2 = [], [], [], []\n",
    "    Q11_set3, Q22_set3, Q12_set3, Q66_set3 = [], [], [], []\n",
    "    \n",
    "    print(f\"\\nRunning {n_iterations} iterations...\")\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Iteration {i+1}/{n_iterations}\")\n",
    "        \n",
    "        # Add Gaussian white noise\n",
    "        noise1 = np.random.randn(*Eps1_orig.shape) * noise_amplitude\n",
    "        noise2 = np.random.randn(*Eps2_orig.shape) * noise_amplitude\n",
    "        noise6 = np.random.randn(*Eps6_orig.shape) * noise_amplitude\n",
    "        \n",
    "        Eps1_noisy = Eps1_orig + noise1\n",
    "        Eps2_noisy = Eps2_orig + noise2\n",
    "        Eps6_noisy = Eps6_orig + noise6\n",
    "        \n",
    "        try:\n",
    "            Q1 = self.virtual_fields_set_1(Eps1_noisy, Eps2_noisy, Eps6_noisy)\n",
    "            Q11_set1.append(Q1[0]); Q22_set1.append(Q1[1])\n",
    "            Q12_set1.append(Q1[2]); Q66_set1.append(Q1[3])\n",
    "            \n",
    "            Q2 = self.virtual_fields_set_2(Eps1_noisy, Eps2_noisy, Eps6_noisy)\n",
    "            Q11_set2.append(Q2[0]); Q22_set2.append(Q2[1])\n",
    "            Q12_set2.append(Q2[2]); Q66_set2.append(Q2[3])\n",
    "            \n",
    "            Q3 = self.virtual_fields_set_3(Eps1_noisy, Eps2_noisy, Eps6_noisy)\n",
    "            Q11_set3.append(Q3[0]); Q22_set3.append(Q3[1])\n",
    "            Q12_set3.append(Q3[2]); Q66_set3.append(Q3[3])\n",
    "            \n",
    "        except (np.linalg.LinAlgError, NotImplementedError):\n",
    "            continue\n",
    "    \n",
    "    # Convert to GPa and store\n",
    "    self.noise_results = {\n",
    "        'set1': {\n",
    "            'Q11': np.array(Q11_set1)/1e3, 'Q22': np.array(Q22_set1)/1e3,\n",
    "            'Q12': np.array(Q12_set1)/1e3, 'Q66': np.array(Q66_set1)/1e3\n",
    "        },\n",
    "        'set2': {\n",
    "            'Q11': np.array(Q11_set2)/1e3, 'Q22': np.array(Q22_set2)/1e3,\n",
    "            'Q12': np.array(Q12_set2)/1e3, 'Q66': np.array(Q66_set2)/1e3\n",
    "        },\n",
    "        'set3': {\n",
    "            'Q11': np.array(Q11_set3)/1e3, 'Q22': np.array(Q22_set3)/1e3,\n",
    "            'Q12': np.array(Q12_set3)/1e3, 'Q66': np.array(Q66_set3)/1e3\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    self._display_noise_statistics(Q_ref)\n",
    "    return self.noise_results\n",
    "\n",
    "def _display_noise_statistics(self, Q_ref=None):\n",
    "    \"\"\"Display noise analysis statistics (PROVIDED)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"STATISTICAL RESULTS\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    params = ['Q11', 'Q22', 'Q12', 'Q66']\n",
    "    \n",
    "    for set_num, set_name in enumerate(['set1', 'set2', 'set3'], 1):\n",
    "        print(f\"\\nVirtual Field Set {set_num}:\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"{'Param':<6} {'Mean':<10} {'Std':<10} {'CV%':<10}\", end=\"\")\n",
    "        if Q_ref is not None:\n",
    "            print(f\" {'Ref':<10} {'Error%':<10}\")\n",
    "        else:\n",
    "            print()\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        for i, param in enumerate(params):\n",
    "            values = self.noise_results[set_name][param]\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            cv_val = (std_val / mean_val) * 100 if mean_val != 0 else 0\n",
    "            \n",
    "            print(f\"{param:<6} {mean_val:<10.3f} {std_val:<10.4f} {cv_val:<10.3f}\", end=\"\")\n",
    "            \n",
    "            if Q_ref is not None:\n",
    "                error_pct = abs(mean_val - Q_ref[i]) / Q_ref[i] * 100\n",
    "                print(f\" {Q_ref[i]:<10.3f} {error_pct:<10.3f}\")\n",
    "            else:\n",
    "                print()\n",
    "\n",
    "IosipescuVFM.run_noise_analysis = run_noise_analysis\n",
    "IosipescuVFM._display_noise_statistics = _display_noise_statistics"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run noise analysis\n",
    "noise_results = vfm.run_noise_analysis(\n",
    "    noise_amplitude=10e-4,\n",
    "    n_iterations=30,\n",
    "    Q_ref=Q_ref\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 5: Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_noise_results(self):\n",
    "    \"\"\"Plot histogram of identified parameters (PROVIDED)\"\"\"\n",
    "    if not self.noise_results:\n",
    "        print(\"No results to plot. Run noise analysis first.\")\n",
    "        return\n",
    "    \n",
    "    params = ['Q11', 'Q22', 'Q12', 'Q66']\n",
    "    param_units = ['GPa', 'GPa', 'GPa', 'GPa']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    colors = ['blue', 'red', 'green']\n",
    "    \n",
    "    for i, param in enumerate(params):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        for j, set_name in enumerate(['set1', 'set2', 'set3']):\n",
    "            data = self.noise_results[set_name][param]\n",
    "            ax.hist(data, alpha=0.6, label=f'Set {j+1}',\n",
    "                   bins=20, density=True, color=colors[j],\n",
    "                   edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_xlabel(f'{param} ({param_units[i]})', fontsize=14)\n",
    "        ax.set_ylabel('Probability Density', fontsize=14)\n",
    "        ax.set_title(f'Distribution of {param}', fontsize=16, fontweight='bold')\n",
    "        ax.legend(fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics text\n",
    "        stats_text = ''\n",
    "        for j, set_name in enumerate(['set1', 'set2', 'set3']):\n",
    "            data = self.noise_results[set_name][param]\n",
    "            stats_text += f'Set {j+1}: Î¼={np.mean(data):.3f}, Ï={np.std(data):.4f}\\n'\n",
    "        \n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n",
    "               fontsize=10, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "IosipescuVFM.plot_noise_results = plot_noise_results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot results\n",
    "vfm.plot_noise_results()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "1. **Which virtual field set gives the most accurate Q12 identification? Why?**\n",
    "\n",
    "2. **Which parameter shows the highest noise sensitivity (highest CV%)? Can you explain why based on the strain field distribution?**\n",
    "\n",
    "3. **Compare the three sets: What are the trade-offs between them?**\n",
    "\n",
    "4. **How would you design a better virtual field if you could choose any kinematically admissible field?**\n",
    "\n",
    "## Bonus Challenges\n",
    "\n",
    "If you finish early, try:\n",
    "\n",
    "1. **Implement a 4th virtual field set** with your own choice of fields\n",
    "2. **Study the effect of noise amplitude** - how does CV% scale with noise?\n",
    "3. **Compute the condition number** of matrix A for each set - does it correlate with noise sensitivity?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
